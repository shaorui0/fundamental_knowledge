先把个人项目和自我介绍梳理好吧，同时，简历中出现的点，都要了解好。

# 自我介绍

- 基本信息：面试官你好，我叫邵瑞，现在北京科技大学研二在读。
- 个人状况：如您所见，现在还在百度实习（【为什么出来找机会？】）。
- 工作经历：在百度后端开发和数据开发都有涉及，内部方向是ToB的，主要是商业广告相关的业务。（【为什么不做数据而做后端】）

## 介绍简历：

简历上列出了四个比较有代表性的任务，其中第一个是我全权负责的。大概涵盖了：
- ETL框架的设计和开发）【为什么需要开发这个框架，百度没有自己的ETL框架吗？】
    - STAR
    - 场景：百度厂内有ETL框架吗？为什么还需要自己写？之前都是怎么处理ETL的？产生这个项目的契机是什么？
    - 任务：
        - 为了方便用户使用，肯定是需要有一个好的『配置端』，
        - 这个调研两个概念，一个process和dataset
        - 还有就是各种过程和数据端的补全了
        - 最后是如何进行例行调度
    - 行动：主要分为三块：
        - 框架的设计，需要有哪些功能支持
        - 整体基本的架构的开发
        - 一些支持性的process和dataset
        以上是执行层面的，之前都是shell配置crontab进行例行调度，也不太方便。
        - 于是我将框架接入airflow的hook完成了框架之间的整合
        这块其实还有个任务，之前也是有框架，但那个我感觉是属于历史遗留问题，使用还行，就是代码写的太乱。于是也进行了一个『打通』的过程（这个过程主要是阅读代码，分析『依赖关系』）
    - 结果：
        - 任务配置层面
        - 例行任务调度层面
- 内部一个大的**决策系统**，我负责开发了最后合并数据流的过程，
    - 难点：这块的难点，主要是一些需要决策的点：
        - redis数据结构的选用。主要对比str和hash，因为是全量获取，所以没必要用hash
        - redis存储方案的选用。单个账户多条流过来，每条流一个k-v和所有的流一个k-v，这里主要和『性能』有关（读取次数）。
        - race condition，全部存在一起可能有『并发』的问题（竞争，读写同时），这块可以用代码保证（加一些，但本质上通过一下代码保证一下就可以了）。
- 一个protobuf的解析服务（【讲一下protobuf（肯定会有的点，这个要讲清楚！）】）
    - 场景：主要是解决了一个**痛点，因为pb的类型过多，各种label和type，用户解析的时候进行要判断类型**，比较麻烦。=== 经常会有一些打平任务，不同层级上获得某些字段。
    - 任务：继续一个解析服务，用户在使用的时候能保证直接获取而不是判断是否存在之类的事情（称之为`happy path`）
    - 行动：于是我设计了一个框架，通过分析业务中不那么明显的层级关系最终梳理出一个架构
    - 结果：使用上非常舒服，user只需要写happy path
- 最后写了web系统的开发，这个算是真正的处理web上的工作了
    - STAR：
    - 场景：我们做广告的，然后选的es保存账户数据（【为什么选es？】），这里的web相当于对数据库进行一个Restful接口的封装，消息主要是es的DSL（可以理解成搜索语言）
        - 关于选择，是从哪些方面来权衡的？（足够写一个blog了）
    - 这快使用的php，上面的都是python。然后主要是es的上层Restful的接口
    - 这块本质上都是业务逻辑，不过也从这里学到了数据库表设计问题（索引）（【介绍一下索引】），缓存（【这里之前是有个拖慢速度的任务，有redis做缓存，但是速度仍然不行，我通过分析，加了一层类变量缓存，速度提升了很多】）
    问你一些web的知识吧（然后开始说什么HTTPs，什么版本的问题）
    问你一些数据库的知识吧，然后基本就是问缓存了

# 关于项目的问题：

1. 遇到的最困难的问题？
2. 怎么解决的？

## 第一个项目：

主要的就是开发那个shell支持吧，相当于在python框架内部插入shell的执行过程
STAR
S: 
- 因为这个框架最基础的功能肯定就是支持一个shell命令的执行了（之前说的原因，一次执行完所有的shell命令肯定是**不好管理的**）
- 线上集群优化的那个问题说一下：
    > 这个到还不是优化了hadoop线上集群的执行过程，而是说，我们本地有一个数据转储的任务，那个任务大概就是依赖多个小时级别的任务。每次转储的过程包括预处理检查，真实的检查，然后就是完整性检查这个过程。通过分析。多任务下载的过程，涉及到hadoop线上集群操作，因为都是线性的，每个任务都要执行一段时间，整体就会执行多个时间。通过分析，我发现这是一个典型的异步下载的过程，通过引入并发的思想，同时将任务一起发到线上。把下载压力给到线上，这样基本就属于单个下载任务了。这个问题倒没有看上去那么直观，主要是每次转储涉及到数据准备充分、真正的转储，以及完整性校验，这个过程都是通过shell线性执行的。当时我提出我的框架可以做这个事情，就迁移上去了


T：
- 支持shell在框架里面执行。单条语句python里面有现成的接口。
- 支持多条语句的支持。**【重点】刚开始想的是自己用管道连接（TODO 介绍一下管道），这里就会产生一个问题，你需要自己解析所有的单条语句，对每条语句进行一个解析，整理好输入、输出、错误，这个工作量是极大的**，显然这里这样做不太好。

A：
- 我们知道，大部分你踩过的坑，其实都已经被人解决了。我通过『调研』，找到airflow里面有个shellOperator，本质也是一个调度的过程
- 通过调研了解到这个是有成熟的处理手段的，就是生成临时脚本然后直接执行。剩下就是注意好步骤异常和错误，同时加入定时器。(这里涉及到了一个多进程并发执行的过程，用的python的上层API)

## 第二个项目：

主要一个决策点：
1. 选用什么redis的数据结构？
2. 选用什么的k-v组织形式？（业务层面），不同的组织形式各自的优缺点？（这是需要对比的）

## 第三个项目：

- 设计层面，到底要设计出什么功能，用户怎么使用更加舒服？（这里调研找到一个python的属性函数，主要是用**装饰器**，让函数的调用像属性调用一样自然（类似java里面的getter、setter））
- 如何让我的服务模块至少能拥有原生protobuf的能力，额外加一些其他调用
    - 使用里面的**动态反射**（通过字符串反射到需要的函数，自定义以后就能调用pb函数了）吧，如果是原生的功能直接在里面执行内置__getitem__

## 第四个项目：

倒也没什么难点，主要的遇到了一个缓存方面的问题
使用了redis作为缓存，但是仍然比较慢，尤其是redis失效的时候，那整个过程就太慢了。
-  通过分析耗时高的子程序（主要是全量数据的获取，和远程es调用相关）
    - redis相比内存读取来说，可能还是慢了点（中间有个远程调用的过程），加了个类变量解决这个问题


---

以上整个过程，可以扩展出很多可以问的知识点：
1. 技术关键字：es、pb、redis、git(rebase, fetch)、docker、~~airflow~~
2. 项目扩展：
- WEB相关：HTTP、return_code、restful
- 并发相关：进程、线程、协程
3. TODO 技术选型：为什么选es，这个你清楚吗？为什么不用RDBMS，以及某些nosql
    - 分层次，包括：特征 => 标签 => 复合标签 => 账户
    - 索引，
    - schema